{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGANDO DADOS\n",
    "\n",
    "# importando dataset\n",
    "dataset = fetch_ucirepo(id=109) # 178 registros e 13 atributos\n",
    "  \n",
    "# coletando as informações\n",
    "data_frame = dataset.data.original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRÉ TRATAMENTO:  178\n",
      "VALORES DUPLICADOS:  0\n",
      "PÓS TRATAMENTO:  178\n"
     ]
    }
   ],
   "source": [
    "# TRATANDO DADOS\n",
    "\n",
    "print(\"PRÉ TRATAMENTO: \", len(data_frame))\n",
    "\n",
    "# removendo colunas com muitos nulos\n",
    "tolerancia = len(data_frame) * 0.7\n",
    "data_frame = data_frame.dropna(axis=1, thresh=tolerancia)\n",
    "\n",
    "# removendo duplicados\n",
    "print(\"VALORES DUPLICADOS: \", data_frame.duplicated().sum())\n",
    "data_frame = data_frame.drop_duplicates()\n",
    "\n",
    "# convertendo colunas categóricas em valores inteiros\n",
    "conversores = {}\n",
    "for coluna in data_frame.columns:\n",
    "    if (data_frame[coluna].dtype == type(object)):\n",
    "        conversor = LabelEncoder()\n",
    "        data_frame[coluna] = conversor.fit_transform(data_frame[coluna])\n",
    "        conversores[coluna] = conversor\n",
    "\n",
    "print(\"PÓS TRATAMENTO: \", len(data_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Alcohol', 'Malicacid', 'Ash', 'Alcalinity_of_ash', 'Magnesium',\n",
      "       'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols',\n",
      "       'Proanthocyanins', 'Color_intensity', 'Hue',\n",
      "       '0D280_0D315_of_diluted_wines', 'Proline', 'class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_frame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIDINDO O DATASET TRATADO\n",
    "\n",
    "atributos = data_frame.drop([\"class\"], axis=1)\n",
    "respostas = data_frame[[\"class\"]]\n",
    "\n",
    "a_treino, a_teste, r_treino, r_teste = train_test_split(atributos, respostas, test_size=0.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIANDO PARÂMETROS PARA OS MODELOS\n",
    "\n",
    "lista_parametros = [\n",
    "    {\"id\": \"1\", \"criterion\": \"gini\", \"max_depth\": None, \"min_samples_split\": 2, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"2\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"3\", \"criterion\": \"entropy\", \"max_depth\": None, \"min_samples_split\": 2, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"5\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APLICANDO MODELO\n",
    "\n",
    "# criando a lista de resultados finais\n",
    "lista_resultados = []\n",
    "\n",
    "for parametros in lista_parametros:\n",
    "    # criando regressor\n",
    "    regressor = tree.DecisionTreeClassifier(\n",
    "        criterion=parametros[\"criterion\"],\n",
    "        max_depth=parametros[\"max_depth\"],\n",
    "        min_samples_split=parametros[\"min_samples_split\"],\n",
    "        min_samples_leaf=parametros[\"min_samples_leaf\"],\n",
    "    )\n",
    "\n",
    "    # treinando o modelo\n",
    "    regressor.fit(a_treino, r_treino)\n",
    "\n",
    "    # prevendo respostas\n",
    "    r_previsao = regressor.predict(a_teste)\n",
    "\n",
    "    # calculando métricas\n",
    "    acuracia = accuracy_score(r_teste, r_previsao)\n",
    "    f1 = f1_score(r_teste, r_previsao, average=\"weighted\")\n",
    "\n",
    "    # salvando resultados\n",
    "    lista_resultados.append([parametros[\"id\"], acuracia, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Identificador  Acurácia  F1-score\n",
      "0             1  0.930556  0.930996\n",
      "1             2  0.930556  0.930996\n",
      "2             3  0.944444  0.944650\n",
      "3             5  0.902778  0.902263\n"
     ]
    }
   ],
   "source": [
    "# EXIBINDO RESULTADOS\n",
    "tabela_resultados = pandas.DataFrame(lista_resultados, columns=[\"Identificador\", \"Acurácia\", \"F1-score\"])\n",
    "print(tabela_resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
