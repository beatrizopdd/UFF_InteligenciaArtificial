{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLETA DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGANDO DADOS\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# importando dataset\n",
    "dataset = fetch_ucirepo(id=848) # 61068 registros e 21 atributos\n",
    "  \n",
    "# coletando as informações\n",
    "data_frame = dataset.data.original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRÉ-PROCESSAMENTO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRÉ TRATAMENTO: 61069 registros e (61069, 21) colunas\n",
      "VALORES DUPLICADOS:  146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PÓS TRATAMENTO: 60923 registros e (60923, 15) colunas\n"
     ]
    }
   ],
   "source": [
    "# TRATANDO DADOS\n",
    "import pandas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(f\"PRÉ TRATAMENTO: {len(data_frame)} registros e {data_frame.shape} colunas\")\n",
    "\n",
    "# removendo colunas com muitos nulos\n",
    "tolerancia = len(data_frame) * 0.7\n",
    "data_frame = data_frame.dropna(axis=1, thresh=tolerancia)\n",
    "\n",
    "\n",
    "# removendo duplicados\n",
    "print(\"VALORES DUPLICADOS: \", data_frame.duplicated().sum())\n",
    "data_frame = data_frame.drop_duplicates()\n",
    "\n",
    "# convertendo colunas categóricas em valores inteiros\n",
    "conversores = {}\n",
    "for coluna in data_frame.columns:\n",
    "    if (data_frame[coluna].dtype == type(object)):\n",
    "        conversor = LabelEncoder()\n",
    "        data_frame[coluna] = conversor.fit_transform(data_frame[coluna])\n",
    "        conversores[coluna] = conversor\n",
    "\n",
    "print(f\"PÓS TRATAMENTO: {len(data_frame)} registros e {data_frame.shape} colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class', 'cap-diameter', 'cap-shape', 'cap-surface', 'cap-color',\n",
      "       'does-bruise-or-bleed', 'gill-attachment', 'gill-color', 'stem-height',\n",
      "       'stem-width', 'stem-color', 'has-ring', 'ring-type', 'habitat',\n",
      "       'season'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_frame.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIVISÃO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIDINDO O DATASET TRATADO\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "atributos = data_frame.drop([\"class\"], axis=1)\n",
    "respostas = data_frame[[\"class\"]]\n",
    "\n",
    "a_treino, a_teste, r_treino, r_teste = train_test_split(atributos, respostas, test_size=0.3, random_state=42)\n",
    "\n",
    "# convertendo de (N, 1) para (N,)\n",
    "r_treino = numpy.ravel(r_treino)\n",
    "r_teste = numpy.ravel(r_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAMANHO DO DATASET TRATADO:  60923\n",
      "CONJUNTO DE TREINO:  (42646, 14)  e  (42646,)\n",
      "CONJUNTO DE TESTE:  (18277, 14)  e  (18277,)\n"
     ]
    }
   ],
   "source": [
    "print(\"TAMANHO DO DATASET TRATADO: \", len(data_frame))\n",
    "print(\"CONJUNTO DE TREINO: \", a_treino.shape, \" e \", r_treino.shape)\n",
    "print(\"CONJUNTO DE TESTE: \", a_teste.shape, \" e \", r_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TREINAMENTO E AVALIAÇÃO DO MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ÁRVORE DE DECISÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIANDO PARÂMETROS PARA O MODELO\n",
    "lista_parametros_ad = [\n",
    "    {\"id\": \"Var_AD_1\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_AD_2\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_AD_3\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_AD_4\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_AD_5\", \"criterion\": \"gini\", \"max_depth\": 20, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_AD_6\", \"criterion\": \"gini\", \"max_depth\": 20, \"min_samples_split\": 10, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_AD_7\", \"criterion\": \"gini\", \"max_depth\": 20, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_AD_8\", \"criterion\": \"gini\", \"max_depth\": 20, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_AD_9\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_AD_10\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_AD_11\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_AD_12\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_AD_13\", \"criterion\": \"entropy\", \"max_depth\": 20, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_AD_14\", \"criterion\": \"entropy\", \"max_depth\": 20, \"min_samples_split\": 10, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_AD_15\", \"criterion\": \"entropy\", \"max_depth\": 20, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_AD_16\", \"criterion\": \"entropy\", \"max_depth\": 20, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APLICANDO MODELO\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# criando a lista de resultados finais\n",
    "lista_resultados_ad = []\n",
    "\n",
    "for parametros in lista_parametros_ad:\n",
    "    # criando classificador\n",
    "    classificador = DecisionTreeClassifier(\n",
    "        criterion=parametros[\"criterion\"],\n",
    "        max_depth=parametros[\"max_depth\"],\n",
    "        min_samples_split=parametros[\"min_samples_split\"],\n",
    "        min_samples_leaf=parametros[\"min_samples_leaf\"],\n",
    "    )\n",
    "\n",
    "    # treinando o modelo\n",
    "    classificador.fit(a_treino, r_treino)\n",
    "\n",
    "    # prevendo respostas\n",
    "    r_previsao_teste = classificador.predict(a_teste)\n",
    "\n",
    "    # calculando métricas\n",
    "    acuracia = accuracy_score(r_teste, r_previsao_teste)\n",
    "    f1 = f1_score(r_teste, r_previsao_teste, average=\"weighted\")\n",
    "\n",
    "    # salvando resultados\n",
    "    lista_resultados_ad.append([parametros[\"id\"], acuracia, f1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Identificador  Acurácia  F1-score\n",
      "0       Var_AD_1  0.918313  0.918539\n",
      "1       Var_AD_2  0.917656  0.917886\n",
      "2       Var_AD_3  0.918203  0.918431\n",
      "3       Var_AD_4  0.917765  0.917995\n",
      "4       Var_AD_5  0.991191  0.991191\n",
      "5       Var_AD_6  0.988565  0.988568\n",
      "6       Var_AD_7  0.990152  0.990152\n",
      "7       Var_AD_8  0.988401  0.988403\n",
      "8       Var_AD_9  0.871368  0.871697\n",
      "9      Var_AD_10  0.870548  0.870878\n",
      "10     Var_AD_11  0.871368  0.871697\n",
      "11     Var_AD_12  0.870548  0.870878\n",
      "12     Var_AD_13  0.994693  0.994693\n",
      "13     Var_AD_14  0.991519  0.991520\n",
      "14     Var_AD_15  0.993817  0.993818\n",
      "15     Var_AD_16  0.991793  0.991793\n"
     ]
    }
   ],
   "source": [
    "# EXIBINDO RESULTADOS\n",
    "tabela_resultados_ad = pandas.DataFrame(lista_resultados_ad, columns=[\"Identificador\", \"Acurácia\", \"F1-score\"])\n",
    "print(tabela_resultados_ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIANDO PARÂMETROS PARA OS MODELOS\n",
    "parametros_rf = [\n",
    "    {\"id\": \"Var_RF_1\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_RF_2\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_RF_3\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_RF_4\", \"criterion\": \"gini\", \"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_RF_5\", \"criterion\": \"gini\", \"max_depth\": 20, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_RF_6\", \"criterion\": \"gini\", \"max_depth\": 20, \"min_samples_split\": 10, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_RF_7\", \"criterion\": \"gini\", \"max_depth\": 20, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_RF_8\", \"criterion\": \"gini\", \"max_depth\": 20, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_RF_9\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_RF_10\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 10, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_RF_11\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_RF_12\", \"criterion\": \"entropy\", \"max_depth\": 10, \"min_samples_split\": 20, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_RF_13\", \"criterion\": \"entropy\", \"max_depth\": 20, \"min_samples_split\": 10, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_RF_14\", \"criterion\": \"entropy\", \"max_depth\": 20, \"min_samples_split\": 10, \"min_samples_leaf\": 10},\n",
    "    {\"id\": \"Var_RF_15\", \"criterion\": \"entropy\", \"max_depth\": 20, \"min_samples_split\": 20, \"min_samples_leaf\": 5},\n",
    "    {\"id\": \"Var_RF_16\", \"criterion\": \"entropy\", \"max_depth\": 20, \"min_samples_split\": 20, \"min_samples_leaf\": 10}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APLICANDO MODELO\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# criando a lista de resultados finais\n",
    "lista_resultados_rf = []\n",
    "\n",
    "for parametros in parametros_rf:\n",
    "    # criando classificador\n",
    "    classificador = RandomForestClassifier(\n",
    "        criterion=parametros[\"criterion\"], \n",
    "        max_depth=parametros[\"max_depth\"], \n",
    "        min_samples_split=parametros[\"min_samples_split\"], \n",
    "        min_samples_leaf=parametros[\"min_samples_leaf\"], \n",
    "        n_estimators=100, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # treinando o modelo\n",
    "    classificador.fit(a_treino, r_treino)\n",
    "\n",
    "    # prevendo respostas\n",
    "    r_previsao = classificador.predict(a_teste)\n",
    "\n",
    "    # calculando métricas\n",
    "    acuracia = accuracy_score(r_teste, r_previsao)\n",
    "    f1 = f1_score(r_teste, r_previsao, average=\"weighted\")\n",
    "\n",
    "    # salvando resultados\n",
    "    lista_resultados_rf.append([parametros[\"id\"], acuracia, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Identificador  Acurácia  F1-score\n",
      "0       Var_RF_1  0.990425  0.990424\n",
      "1       Var_RF_2  0.990918  0.990916\n",
      "2       Var_RF_3  0.990699  0.990699\n",
      "3       Var_RF_4  0.990918  0.990916\n",
      "4       Var_RF_5  0.998906  0.998906\n",
      "5       Var_RF_6  0.998523  0.998523\n",
      "6       Var_RF_7  0.998960  0.998960\n",
      "7       Var_RF_8  0.998523  0.998523\n",
      "8       Var_RF_9  0.988401  0.988400\n",
      "9      Var_RF_10  0.985282  0.985285\n",
      "10     Var_RF_11  0.990042  0.990044\n",
      "11     Var_RF_12  0.985282  0.985285\n",
      "12     Var_RF_13  0.998960  0.998960\n",
      "13     Var_RF_14  0.998304  0.998304\n",
      "14     Var_RF_15  0.998851  0.998851\n",
      "15     Var_RF_16  0.998304  0.998304\n"
     ]
    }
   ],
   "source": [
    "# EXIBINDO RESULTADOS\n",
    "tabela_resultados_rf = pandas.DataFrame(lista_resultados_rf, columns=[\"Identificador\", \"Acurácia\", \"F1-score\"])\n",
    "print(tabela_resultados_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rede Neural Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIANDO PARÂMETROS PARA OS MODELOS\n",
    "\n",
    "lista_parametros_mlp = [\n",
    "    {\"id\": \"Var_MLP_1\", \"hidden_layer_sizes\": (50,), \"activation\": \"relu\"},\n",
    "    {\"id\": \"Var_MLP_2\", \"hidden_layer_sizes\": (50,), \"activation\": \"tanh\"},\n",
    "    {\"id\": \"Var_MLP_3\", \"hidden_layer_sizes\": (50,), \"activation\": \"logistic\"},\n",
    "    {\"id\": \"Var_MLP_4\", \"hidden_layer_sizes\": (100,), \"activation\": \"relu\"},\n",
    "    {\"id\": \"Var_MLP_5\", \"hidden_layer_sizes\": (100,), \"activation\": \"tanh\"},\n",
    "    {\"id\": \"Var_MLP_6\", \"hidden_layer_sizes\": (100,), \"activation\": \"logistic\"},\n",
    "    {\"id\": \"Var_MLP_7\", \"hidden_layer_sizes\": (150,), \"activation\": \"relu\"},\n",
    "    {\"id\": \"Var_MLP_8\", \"hidden_layer_sizes\": (150,), \"activation\": \"tanh\"},\n",
    "    {\"id\": \"Var_MLP_9\", \"hidden_layer_sizes\": (150,), \"activation\": \"logistic\"},\n",
    "    {\"id\": \"Var_MLP_10\", \"hidden_layer_sizes\": (50, 50), \"activation\": \"relu\"},\n",
    "    {\"id\": \"Var_MLP_11\", \"hidden_layer_sizes\": (50, 50), \"activation\": \"tanh\"},\n",
    "    {\"id\": \"Var_MLP_12\", \"hidden_layer_sizes\": (50, 50), \"activation\": \"logistic\"},\n",
    "    {\"id\": \"Var_MLP_13\", \"hidden_layer_sizes\": (100, 100), \"activation\": \"relu\"},\n",
    "    {\"id\": \"Var_MLP_14\", \"hidden_layer_sizes\": (100, 100), \"activation\": \"tanh\"},\n",
    "    {\"id\": \"Var_MLP_15\", \"hidden_layer_sizes\": (100, 100), \"activation\": \"logistic\"},\n",
    "    {\"id\": \"Var_MLP_16\", \"hidden_layer_sizes\": (150, 150), \"activation\": \"relu\"},\n",
    "    {\"id\": \"Var_MLP_17\", \"hidden_layer_sizes\": (150, 150), \"activation\": \"tanh\"},\n",
    "    {\"id\": \"Var_MLP_18\", \"hidden_layer_sizes\": (150, 150), \"activation\": \"logistic\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APLICANDO MODELO\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# criando a lista de resultados finais\n",
    "lista_resultados_mlp = []\n",
    "\n",
    "for parametros in lista_parametros_mlp:\n",
    "    # criando classificador\n",
    "    classificador = MLPClassifier(\n",
    "        hidden_layer_sizes=parametros[\"hidden_layer_sizes\"],\n",
    "        activation=parametros[\"activation\"],\n",
    "        max_iter=500,\n",
    "    )\n",
    "\n",
    "    # treinando o modelo\n",
    "    classificador.fit(a_treino, r_treino)\n",
    "\n",
    "    # prevendo respostas\n",
    "    r_previsao = classificador.predict(a_teste)\n",
    "\n",
    "    # calculando métricas\n",
    "    acuracia = accuracy_score(r_teste, r_previsao)\n",
    "    f1 = f1_score(r_teste, r_previsao, average=\"weighted\")\n",
    "\n",
    "    # salvando resultados\n",
    "    lista_resultados_mlp.append([parametros[\"id\"], acuracia, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Identificador  Acurácia  F1-score\n",
      "0      Var_MLP_1  0.990808  0.990806\n",
      "1      Var_MLP_2  0.996881  0.996882\n",
      "2      Var_MLP_3  0.997757  0.997757\n",
      "3      Var_MLP_4  0.997538  0.997538\n",
      "4      Var_MLP_5  0.998796  0.998796\n",
      "5      Var_MLP_6  0.998851  0.998851\n",
      "6      Var_MLP_7  0.998030  0.998031\n",
      "7      Var_MLP_8  0.998632  0.998632\n",
      "8      Var_MLP_9  0.999070  0.999070\n",
      "9     Var_MLP_10  0.997811  0.997812\n",
      "10    Var_MLP_11  0.997647  0.997647\n",
      "11    Var_MLP_12  0.994091  0.994093\n",
      "12    Var_MLP_13  0.998960  0.998960\n",
      "13    Var_MLP_14  0.997428  0.997428\n",
      "14    Var_MLP_15  0.996334  0.996333\n",
      "15    Var_MLP_16  0.999070  0.999070\n",
      "16    Var_MLP_17  0.999289  0.999289\n",
      "17    Var_MLP_18  0.997374  0.997374\n"
     ]
    }
   ],
   "source": [
    "# EXIBINDO RESULTADOS\n",
    "tabela_resultados_mlp = pandas.DataFrame(lista_resultados_mlp, columns=[\"Identificador\", \"Acurácia\", \"F1-score\"])\n",
    "print(tabela_resultados_mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
